{"./":{"url":"./","title":"Introduction","keywords":"","body":"# Java面试知识整理贡献者：# Java面试知识整理 本文档使用 Gitbook 制作，Github 仓库地址。 所有引用内容版权归原作者所有。 使用 知识共享“署名-非商业性使用-相同方式共享 3.0 中国大陆”许可协议 授权。 贡献者： weylan "},"basic/basic-skill.html":{"url":"basic/basic-skill.html","title":"基本功","keywords":"","body":"面向对象特征final, finally, finalize 的区别int 和 Integer 有什么区别重载和重写的区别抽象类和接口有什么区别说说反射的用途及实现说说自定义注解的场景及实现HTTP 请求的 GET 与 POST 方式的区别session 与 cookie 区别JDBC 流程面向对象特征 封装，继承，多态和抽象 封装 封装给对象提供了隐藏内部特性和行为的能力。对象提供一些能被其他对象访问的方法 来改 变它内部的数据。在 Java 当中，有 3 种修饰符： public， private 和 protected。每一 种修饰符 给其他的位于同一个包或者不同包下面对象赋予了不同的访问权限。 下面列出了使用封装的一些好处： 通过隐藏对象的属性来保护对象内部的状态。 提高了代码的可用性和可维护性，因为对象的行为可以被单独的改变或者是扩展。 禁止对象之间的不良交互提高模块化 继承 继承给对象提供了从基类获取字段和方法的能力。继承提供了代码的重用行，也可以在 不修改类的情况下给现存的类添加新特性。 多态 多态是编程语言给不同的底层数据类型做相同的接口展示的一种能力。一个多态类型上 的操作可以应用到其他类型的值上面。 抽象 抽象是把想法从具体的实例中分离出来的步骤，因此，要根据他们的功能而不是实现细 节来创建类。 Java 支持创建只暴漏接口而不包含方法实现的抽象的类。这种抽象技术 的主要目的是把类的行为和实现细节分离开。 final, finally, finalize 的区别 final 修饰符（关键字）如果一个类被声明为final，意味着它不能再派生出新的子类，不能作 为父类被继承。因此一个类不能既被声明为 abstract的，又被声明为final的。将变量或 方法声明为final，可以保证它们在使用中不被改变。被声明为final的变量必须在声明时 给定初值，而在以后的引用中只能读取，不可修改。被声明为final的方法也同样只能使 用，不能重载。 finally 在异常处理时提供 finally 块来执行任何清除操作。如果抛出一个异常，那么相匹配的 catch 子句就会执行，然后控制就会进入 finally 块（如果有的话）。 finalize 方法名。Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前 做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象 调用的。它是在 Object 类中定义的，因此所有的类都继承了它。子类覆盖 finalize() 方 法以整理系统资源或者执行其他清理工作。finalize() 方法是在垃圾收集器删除对象之前 对这个对象调用的。 int 和 Integer 有什么区别 int 是基本数据类型 Integer是其包装类，注意是一个类。 为什么要提供包装类呢？？？ 一是为了在各种类型间转化，通过各种方法的调用。否则 你无法直接通过变量转化。 比如，现在int要转为String int a=0; String result=Integer.toString(a); 在java中包装类，比较多的用途是用在于各种数据类型的转化中。 我写几个demo //通过包装类来实现转化的 int num=Integer.valueOf(\"12\"); int num2=Integer.parseInt(\"12\"); double num3=Double.valueOf(\"12.2\"); double num4=Double.parseDouble(\"12.2\"); //其他的类似。通过基本数据类型的包装来的valueOf和parseXX来实现String转为XX String a=String.valueOf(\"1234\");//这里括号中几乎可以是任何类型 String b=String.valueOf(true); String c=new Integer(12).toString();//通过包装类的toString()也可以 String d=new Double(2.3).toString(); 再举例下。比如我现在要用泛型 List nums; 这里<>需要类。如果你用int。它会报错的。 重载和重写的区别 override（重写） 方法名、参数、返回值相同。 子类方法不能缩小父类方法的访问权限。 子类方法不能抛出比父类方法更多的异常(但子类方法可以不抛出异常)。 存在于父类和子类之间。 方法被定义为final不能被重写。 overload（重载） 参数类型、个数、顺序至少有一个不相同。 不能重载只有返回值不同的方法名。 存在于父类和子类、同类中。 区别 重载 重写 英文 Overloading Overiding 定义 方法名称相同，参数的类型或个数不同 方法名称、参数类型、返回值类型全部相同 权限 对权限没要求 被重写的方法不能拥有更严格的权限 范围 发生在一个类中 发生在继承类中 抽象类和接口有什么区别 接口是公开的，里面不能有私有的方法或变量，是用于让别人使用的，而抽象类是可以有私 有方法或私有变量的， 另外，实现接口的一定要实现接口里定义的所有方法，而实现抽象类可以有选择地重写需要 用到的方法，一般的应用里，最顶级的是接口，然后是抽象类实现接口，最后才到具体类实 现。 还有，接口可以实现多重继承，而一个类只能继承一个超类，但可以通过继承多个接口实现 多重继承，接口还有标识（里面没有任何方法，如Remote接口）和数据共享（里面的变量 全是常量）的作用。 说说反射的用途及实现 Java反射机制主要提供了以下功能：在运行时构造一个类的对象；判断一个类所具有的成 员变量和方法；调用一个对象的方法；生成动态代理。反射最大的应用就是框架 Java反射的主要功能： 确定一个对象的类 取出类的modifiers,数据成员,方法,构造器,和超类. 找出某个接口里定义的常量和方法说明. 创建一个类实例,这个实例在运行时刻才有名字(运行时间才生成的对象). 取得和设定对象数据成员的值,如果数据成员名是运行时刻确定的也能做到. 在运行时刻调用动态对象的方法. 创建数组,数组大小和类型在运行时刻才确定,也能更改数组成员的值. 反射的应用很多，很多框架都有用到 spring 的 ioc/di 也是反射… javaBean和jsp之间调用也是反射… struts的 FormBean 和页面之间…也是通过反射调用… JDBC 的 classForName()也是反射… hibernate的 find(Class clazz) 也是反射… 反射还有一个不得不说的问题，就是性能问题，大量使用反射系统性能大打折扣。怎么使用 使你的系统达到最优就看你系统架构和综合使用问题啦，这里就不多说了。 来源：http://uule.iteye.com/blog/1423512 说说自定义注解的场景及实现 （此题自由发挥，就看你对注解的理解了!==）登陆、权限拦截、日志处理，以及各种Java 框架，如Spring，Hibernate，JUnit 提到注解就不能不说反射，Java自定义注解是通过运行 时靠反射获取注解。实际开发中，例如我们要获取某个方法的调用日志，可以通过 AOP（动态代理机制）给方法添加切面，通过反射来获取方法包含的注解，如果包含日志 注解，就进行日志记录。 HTTP 请求的 GET 与 POST 方式的区别 GET方法会把名值对追加在请求的URL后面。因为URL对字符数目有限制，进而限制了用在 客户端请求的参数值的数目。并且请求中的参数值是可见的，因此，敏感信息不能用这种方 式传递。 POST方法通过把请求参数值放在请求体中来克服GET方法的限制，因此，可以发送的参数 的数目是没有限制的。最后，通过POST请求传递的敏感信息对外部客户端是不可见的。 参考：https://www.cnblogs.com/wangli­66/p/5453507.html session 与 cookie 区别 cookie 是 Web 服务器发送给浏览器的一块信息。浏览器会在本地文件中给每一个 Web 服 务 器存储 cookie。以后浏览器在给特定的 Web 服务器发请求的时候，同时会发送所有为该服 务器存储的 cookie。下面列出了 session 和 cookie 的区别： 无论客户端浏览器做怎么样的设置，session都应该能正常工作。客户端可以选择禁用 cookie， 但是， session 仍然是能够工作的，因为客户端无法禁用服务端的 session。 JDBC 流程 加载JDBC驱动程序： 在连接数据库之前，首先要加载想要连接的数据库的驱动到JVM（Java虚拟机）， 这通过java.lang.Class类的静态方法forName(String className)实现。 例如： try{ //加载MySql的驱动类 Class.forName(\"com.mysql.jdbc.Driver\") ; }catch(ClassNotFoundException e){ System.out.println(\"找不到驱动程序类 ，加载驱动失败！\"); e.printStackTrace() ; } 成功加载后，会将Driver类的实例注册到DriverManager类中。 提供JDBC连接的URL 连接URL定义了连接数据库时的协议、子协议、数据源标识。 书写形式：协议：子协议：数据源标识 协议：在JDBC中总是以jdbc开始 子协议：是桥连接的驱动程序或是数据库管理系统名称。 数据源标识：标记找到数据库来源的地址与连接端口。 例如： jdbc:mysql://localhost:3306/test? useUnicode=true&characterEncoding=gbk;useUnicode=true;（MySql的连接URL） //表示使用Unicode字符集。如果characterEncoding设置为 gb2312或GBK，本参数必须设置 为true 。characterEncoding=gbk：字符编码方式。 创建数据库的连接 要连接数据库，需要向java.sql.DriverManager请求并获得Connection对象， 该对象就 代表一个数据库的连接。 使用DriverManager的getConnectin(String url , String username , String password )方 法传入指定的欲连接的数据库的路径、数据库的用户名和 密码来获得。 例如： //连接MySql数据库，用户名和密码都是root. String url = \"jdbc:mysql://localhost:3306/test\" ; String username = \"root\" ; String password = \"root\" ; try{ Connection con = DriverManager.getConnection(url , username , password ) ; }catch(SQLException se){ System.out.println(\"数据库连接失败！\"); se.printStackTrace() ; 创建一个Statement 要执行SQL语句，必须获得java.sql.Statement实例，Statement实例分为以下3 种类型： 1、执行静态SQL语句。通常通过Statement实例实现。 2、执行动态SQL语句。通常通过PreparedStatement实例实现。 3、执行数据库存储过程。通常通过CallableStatement实例实现。 具体的实现方式： Statement stmt = con.createStatement() ; PreparedStatement pstmt = con.prepareStatement(sql) ; CallableStatement cstmt = con.prepareCall(\"{CALL demoSp(? , ?)}\") ; 执行SQL语句 Statement接口提供了三种执行SQL语句的方法：executeQuery 、executeUpdate 和execute 1、ResultSet executeQuery(String sqlString)：执行查询数据库的SQL语句 ，返回一个结 果集（ResultSet）对象。 2、int executeUpdate(String sqlString)：用于执行INSERT、UPDATE或 DELETE语句以及 SQL DDL语句，如：CREATE TABLE和DROP TABLE等 3、execute(sqlString):用于执行返回多个结果集、多个更新计数或二者组合的 语句。 具体 实现的代码： ResultSet rs = stmt.executeQuery(“SELECT * FROM …”) ; int rows = stmt.executeUpdate(“INSERT INTO …”) ; boolean flag = stmt.execute(String sql) ; 处理结果 两种情况： 1、执行更新返回的是本次操作影响到的记录数。 2、执行查询返回的结果是一个ResultSet对象。 • ResultSet包含符合SQL语句中条件的所有行，并且它通过一套get方法提供了对这些 行中 数据的访问。 • 使用结果集（ResultSet）对象的访问方法获取数据： while(rs.next()){ String name = rs.getString(“name”) ; String pass = rs.getString(1) ; // 此方法比较高效 } //（列是从左到右编号的，并且从列1开始） 关闭JDBC对象 操作完成以后要把所有使用的JDBC对象全都关闭，以释放JDBC资源，关闭顺序和声 明顺 序相反： 1、关闭记录集 2、关闭声明 3、关闭连接对象 if(rs != null){ // 关闭记录集 try{ rs.close() ; }catch(SQLException e){ e.printStackTrace() ; } } if(stmt != null){ // 关闭声明 try{ stmt.close() ; }catch(SQLException e){ e.printStackTrace() ; } } if(conn != null){ // 关闭连接对象 try{ conn.close() ; }catch(SQLException e){ e.printStackTrace() ; } } "},"basic/collection.html":{"url":"basic/collection.html","title":"集合","keywords":"","body":""},"basic/thread.html":{"url":"basic/thread.html","title":"线程","keywords":"","body":"创建线程的方式及实现sleep() 、join（）、yield（）有什么区别说说 CountDownLatch 原理说说 CyclicBarrier 原理创建线程的方式及实现 Java中创建线程主要有三种方式： 一、继承Thread类创建线程类 （1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完 成的任务。因此把run()方法称为执行体。 （2）创建Thread子类的实例，即创建了线程对象。 （3）调用线程对象的start()方法来启动该线程。 package com.thread; public class FirstThreadTest extends Thread{ int i = 0; //重写run方法，run方法的方法体就是现场执行体 public void run() { for(;i 上述代码中Thread.currentThread()方法返回当前正在执行的线程对象。getName()方法返 回调用该方法的线程的名字。 二、通过Runnable接口创建线程类 （1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是 该线程的线程执行体。 （2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread对象，该 Thread对象才是真正的线程对象。 （3）调用线程对象的start()方法来启动该线程。 package com.thread; public class RunnableThreadTest implements Runnable { private int i; public void run() { for(i = 0;i 三、通过Callable和Future创建线程 （1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且 有返回值。 （2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对 象封装了该Callable对象的call()方法的返回值。 （3）使用FutureTask对象作为Thread对象的target创建并启动新线程。 （4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值 package com.thread; import java.util.concurrent.Callable; import java.util.concurrent.ExecutionException; import java.util.concurrent.FutureTask; public class CallableThreadTest implements Callable { public static void main(String[] args) { CallableThreadTest ctt = new CallableThreadTest(); FutureTask ft = new FutureTask<>(ctt); for(int i = 0;i 创建线程的三种方式的对比 采用实现Runnable、Callable接口的方式创见多线程时， 优势是： 线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。 在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同 一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面 向对象的思想。 劣势是： 编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。 使用继承Thread类的方式创建多线程时优势是： 编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this 即可获得当前线程。 线程类已经继承了Thread类，所以不能再继承其他父类 sleep() 、join（）、yield（）有什么区别 1、sleep()方法 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度 程序精度和准确性的影响。 让其他线程有机会继续执行，但它并不释放对象锁。也就是如 果有Synchronized同步块，其他线程仍然不能访问共享数据。注意该方法要捕获异常 比如有两个线程同时执行(没有Synchronized)，一个线程优先级为MAX_PRIORITY，另一 个为MIN_PRIORITY，如果没有Sleep()方法，只有高优先级的线程执行完成后，低优先级 的线程才能执行；但当高优先级的线程sleep(5000)后，低优先级就有机会执行了。 总之，sleep()可以使低优先级的线程得到执行的机会，当然也可以让同优先级、高优先级的 线程有执行的机会。 2、yield()方法 yield()方法和sleep()方法类似，也不会释放“锁标志”，区别在于，它没有参数，即yield()方 法只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态 后马上又被执行，另外yield()方法只能使同优先级或者高优先级的线程得到执行机会，这也 和sleep()方法不同。 3、join()方法 Thread的非静态方法join()让一个线程B“加入”到另外一个线程A的尾部。在A执行完毕之前， B不能工作。 Thread t = new MyThread(); t.start(); t.join(); 保证当前线程停止执行，直到该线程所加入的线程完成为止。然而，如果它加入的线程没有 存活，则当前线程不需要停止。 说说 CountDownLatch 原理 参考： 分析CountDownLatch的实现原理 什么时候使用CountDownLatch Java并发编程：CountDownLatch、CyclicBarrier和Semaphore 说说 CyclicBarrier 原理 "},"basic/lock.html":{"url":"basic/lock.html","title":"锁机制","keywords":"","body":""},"basic/jvm.html":{"url":"basic/jvm.html","title":"JVM","keywords":"","body":"一、 Java内存区域常见面试题1. 运行时数据区域1.1程序计数器(线程私有)1.2 虚拟机栈(线程私有)1.3 本地方法栈(线程私有)1.4 方法区（线程共享）1.5 堆(线程共享)1.6 运行时常量池(线程共享)1.7 直接内存二、 JVM垃圾回收机制常见面试题1 概览2. 内存是如何分配和回收的？2.1对象优先在eden区分配2.2 大对象直接进入老年代2.3 长期存活的对象进入老年代3. 如何确定哪些垃圾需要回收?3.1 引用计数法3.2 可达性分析(根搜索算法)3.3 关于引用3.4 不可达对象并非\"非死不可\"3.5 如何判断一个常量是废弃常量3.6 如何判断一个类是无用的类4. 有哪些垃圾回收算法?4.1 标记清除算法（Mark-Sweep）4.2 复制算法（copying）4.3 标记整理算法(Mark-Compact)4.4 分代收集算法5. 有哪些GC垃圾收集器?5.1 Serial 垃圾收集器（单线程、复制算法）5.2 ParNew 垃圾收集器（Serial+多线程）5.3 Parallel Scavenge 收集器（多线程复制算法、高效）5.4 Serial Old 收集器（单线程标记整理算法 ）5.5 Parallel Old 收集器（多线程标记整理算法）5.6 CMS 收集器（多线程标记清除算法）5.7 G1 收集器6. GC 触发条件及优化6.1 Minor GC ,Major GC, Full GC 有什么不同？6.2 Full GC 触发条件及优化参考一、 Java内存区域 常见面试题 介绍下 Java 内存区域（运行时数据区） Java 对象的创建过程（五步，建议能默写出来并且要知道每一步虚拟机做了什么） 对象的访问定位的两种方式（句柄和直接指针两种方式） String 类和常量池 8 种基本类型的包装类和常量池 1. 运行时数据区域 ​ Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK. 1.8 和之前的版本略有不同。 ​ JVM 内存区域主要分为线程私有区域【程序计数器、虚拟机栈、本地方法区】、线程共享区域【JAVA 堆、方法区】、直接内存。 线程私有数据区域生命周期与线程相同, 依赖用户线程的 启动/结束 而 创建/销毁 (在 Hotspot VM 内, 每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的生/死对应)。 1.1程序计数器(线程私有) 一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的 程序计数器，这类内存也称为“线程私有”的内存。 正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如 果还是 Native 方法，则为空。 这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域。 1.2 虚拟机栈(线程私有) 是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame） 用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成 的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接 (Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。栈帧随着方法调用而创 建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异 常）都算作方法结束。 1.3 本地方法栈(线程私有) 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。 1.4 方法区（线程共享） 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 方法区和永久代的关系 《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。 HotSpot 对方法区的实现在不同版本也有所不同: java7之前，方法区位于永久代(PermGen)，永久代和堆相互隔离，永久代的大小在启动JVM时可以设置一个固定值，不可变； java7中，存储在永久代的部分数据就已经转移到Java Heap或者Native memory。但永久代仍存在于JDK 1.7中，并没有完全移除，譬如符号引用(Symbols)转移到了native memory；字符串常量(interned strings)转移到了Java heap；类的静态变量(class statics)转移到了Java heap。 java8中，取消永久代，新增元空间(Metaspace)，其实在这两者之间存储的内容几乎没怎么变化，而是在内存限制、垃圾回收等机制上改变较大。元空间的出现就是为了解决突出的类和类加载器元数据过多导致的OOM问题，而从jdk7中开始永久代经过对方法区的分裂后已经几乎只存储类和类加载器的元数据信息了，到了jdk8，元空间中也是存储这些信息，而符号引用、字符串常量等存储位置与jdk7一致，还是“分裂”的方法区。 Native memory：本地内存，也称为C-Heap，是供JVM自身进程使用的。当Java Heap空间不足时会触发GC，但Native memory空间不够却不会触发GC。 常用参数 JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小 -XX:PermSize=N //方法区 (永久代) 初始大小 -XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen 相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。 JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 下面是一些常用参数： -XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小） -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。 为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢? 整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到 java.lang.OutOfMemoryError。你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。 当然这只是其中一个原因，还有很多底层的原因，这里就不提了。 1.5 堆(线程共享) Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 新生代 是用来存放新生的对象。一般占据堆的 1/3 空间。由于频繁创建对象，所以新生代会频繁触发 MinorGC 进行垃圾回收。新生代又分为 Eden 区、ServivorFrom、ServivorTo 三个区。 Eden 区 Java 新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老年代）。当 Eden 区内存不够的时候就会触发 MinorGC，对新生代区进行一次垃圾回收。 ServivorFrom 上一次 GC 的幸存者，作为这一次 GC 的被扫描者。 ServivorTo 保留了一次 MinorGC 过程中的幸存者。 MinorGC 的过程（复制->清空->互换） MinorGC 采用复制算法。 eden、servicorFrom 复制到 ServicorTo，年龄+1 首先，把 Eden 和 ServivorFrom 区域中存活的对象复制到 ServicorTo 区域（如果有对象的年 龄以及达到了老年的标准(默认为 15 岁)，则赋值到老年代区），同时把这些对象的年龄+1（如果 ServicorTo 不够位置了就放到老年区）; 清空 eden、servicorFrom 然后，清空 Eden 和 ServicorFrom 中的对象; ServicorTo 和 ServicorFrom 互换 最后，ServicorTo 和 ServicorFrom 互换，原 ServicorTo 成为下一次 GC 时的 ServicorFrom 区。 老年代 主要存放应用程序中生命周期长的内存对象。 老年代的对象比较稳定，所以 MajorGC 不会频繁执行。在进行 MajorGC 前一般都先进行了一次 MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足 够大的连续空间分配给新创建的较大对象时也会提前触发一次 MajorGC 进行垃圾回收腾出空间。 MajorGC 采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没 有标记的对象。MajorGC 的耗时比较长，因为要扫描再回收。MajorGC 会产生内存碎片，为了减 少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的 时候，就会抛出 OOM（Out of Memory）异常。 1.6 运行时常量池(线程共享) 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用） 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 JDK1.7 后,移除了方法区,运行时常量池和字符串常量池都被放在堆中。 1.7 直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。 二、 JVM垃圾回收机制 常见面试题 如何判断对象是否死亡（两种方法）。 简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。 如何判断一个常量是废弃常量 如何判断一个类是无用的类 垃圾收集有哪些算法，各自的特点？ HotSpot 为什么要分为新生代和老年代？ 常见的垃圾回收器有那些？ 介绍一下 CMS,G1 收集器。 Minor Gc 和Full GC 有什么不同呢？ 1 概览 java内存是自动管理的，但当需要排查各种内存溢出问题、垃圾收集成为系统达到更高并发的瓶颈时，我们就需要对这些“自动化”的技术实施必要的监控和调节。 需要了解 内存是如何分配和回收的？哪些垃圾需要回收？什么时候回收？怎么回收？ 2. 内存是如何分配和回收的？ ​ Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。 ​ Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 堆的基本内存结构： ​ 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s1(\"To\")，并且对象的年龄还会加 1(Eden 区->Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。经过这次GC后，Eden区和\"From\"区已经被清空。这个时候，\"From\"和\"To\"会交换他们的角色，也就是新的\"To\"就是上次GC前的“From”，新的\"From\"就是上次GC前的\"To\"。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，\"To\"区被填满之后，会将所有对象移动到年老代中。 2.1对象优先在eden区分配 ​ 目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 ​ 大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC. 2.2 大对象直接进入老年代 ​ 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 为什么要这样呢？ ​ 为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。 2.3 长期存活的对象进入老年代 ​ 既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。 ​ 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 ​ 为了更好的适应不同程序的内存情况，虚拟机不是永远要求对象年龄必须达到了某个值才能进入老年代，如果 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需达到要求的年龄。 3. 如何确定哪些垃圾需要回收? 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。 3.1 引用计数法 在 Java 中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收。简单说，即一个对象如果没有任何与之关联的引用，即他们的引用计数都不为 0，则说明对象不太可能再被用到，那么这个对象就是可回收对象。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。 public class ReferenceCountingGc { Object instance = null; public static void main(String[] args) { ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; } } 3.2 可达性分析(根搜索算法) 为了解决引用计数法的循环引用问题，Java 使用了可达性分析的方法。通过一系列的“GC roots” 对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。 要注意的是，不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记 过程。两次标记后仍然是可回收对象，则将面临回收。 3.3 关于引用 无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。 JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。 JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱） 3.3.1 强引用 以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 3.3.2 软引用 如果一个对象只具有软引用，那就类似于可有可无的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。 3.3.3 弱引用 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。 3.3.4 虚引用 \"虚引用\"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 3.4 不可达对象并非\"非死不可\" 即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。 被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。 3.5 如何判断一个常量是废弃常量 运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？ 假如在常量池中存在字符串 \"abc\"，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池。 3.6 如何判断一个类是无用的类 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？ 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 4. 有哪些垃圾回收算法? 4.1 标记清除算法（Mark-Sweep） 最基础的垃圾回收算法，分为两个阶段，标注和清除。标记阶段标记出所有需要回收的对象，清 除阶段回收被标记的对象所占用的空间。如图: 从图中我们就可以发现，该算法最大的问题是内存碎片化严重，后续可能发生大对象不能找到可 利用空间的问题。 4.2 复制算法（copying） 为了解决 Mark-Sweep 算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小 的两块。每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用 的内存清掉，如图： 这种算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原 本的一半。且存活对象增多的话，Copying 算法的效率会大大降低。 4.3 标记整理算法(Mark-Compact) 结合了以上两个算法，为了避免缺陷而提出。标记阶段和 Mark-Sweep 算法相同，标记后不是清 理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。如图： 4.4 分代收集算法 当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 5. 有哪些GC垃圾收集器? ​ Java 堆内存被划分为新生代和年老代两部分，新生代主要使用复制和标记-清除垃圾回收算法；老代主要使用标记-整理垃圾回收算法，因此 java 虚拟中针对新生代和年老代分别提供了多种不同的垃圾收集器，JDK1.6 中 Sun HotSpot 虚拟机的垃圾收集器如下: 5.1 Serial 垃圾收集器（单线程、复制算法） Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ \"Stop The World\" ），直到它收集结束。 Serial 垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限 定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial 垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。 5.2 ParNew 垃圾收集器（Serial+多线程） ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。 ParNew 收集器默认开启和 CPU 数目相同的线程数，可以通过-XX:ParallelGCThreads 参数来限 制垃圾收集器的线程数。【Parallel：平行的】 ParNew虽然是除了多线程外和Serial 收集器几乎完全一样，但是ParNew垃圾收集器是很多 java 虚拟机运行在 Server 模式下新生代的默认垃圾收集器. 并行和并发概念补充： 并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 5.3 Parallel Scavenge 收集器（多线程复制算法、高效） Parallel Scavenge 收集器也是使用复制算法的多线程收集器，它看上去几乎和ParNew都一样。 那么它有什么特别之处呢？ -XX:+UseParallelGC 使用 Parallel 收集器+ 老年代串行 -XX:+UseParallelOldGC 使用 Parallel 收集器+ 老年代并行 Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 5.4 Serial Old 收集器（单线程标记整理算法 ） Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。 新生代 Serial 与年老代 Serial Old 搭配垃圾收集过程图： Scavenge/ParNew 与年老代 Serial Old 搭配垃圾收集过程图： 5.5 Parallel Old 收集器（多线程标记整理算法） Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。 新生代 Parallel Scavenge 和年老代 Parallel Old 收集器搭配运行过程图： 5.6 CMS 收集器（多线程标记清除算法） CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对为标记的区域做清扫。 CMS 收集器工作过程： CMS是一款优秀的垃圾收集器,主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 5.7 G1 收集器 G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征. 相比与 CMS 收集器，G1 收集器两个最突出的改进是: 基于标记-整理算法，不产生内存碎片。 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域(Region)，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾 最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。 G1收集器具有以下特点: 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记--清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。 G1 收集器的运作大致分为以下几个步骤： 初始标记 并发标记 最终标记 筛选回收 6. GC 触发条件及优化 6.1 Minor GC ,Major GC, Full GC 有什么不同？ 针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种： Partial GC：并不收集整个GC堆的模式 Young GC：只收集young gen的GC Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式 Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式 Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。 Major GC通常是跟full GC是等价的，收集整个GC堆。但因为HotSpot VM发展了这么多年，外界对各种名词的解读已经完全混乱了，当有人说“major GC”的时候一定要问清楚他想要指的是上面的full GC还是old gen。 最简单的分代式GC策略，按HotSpot VM的serial GC的实现来看，触发条件是： young GC：当young gen中的eden区分配满的时候触发。注意young GC中有部分存活对象会晋升到old gen，所以young GC后old gen的占用量通常会有所升高。 full GC：当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC而是转为触发full GC（因为HotSpot VM的GC里，除了CMS的concurrent collection之外，其它能收集old gen的GC都会同时收集整个GC堆，包括young gen，所以不需要事先触发一次单独的young GC）；或者，如果有perm gen的话，要在perm gen分配空间但已经没有足够空间时，也要触发一次full GC；或者System.gc()、heap dump带GC，默认也是触发full GC。 HotSpot VM里其它非并发GC的触发条件复杂一些，不过大致的原理与上面说的其实一样。当然也总有例外。Parallel Scavenge（-XX:+UseParallelGC）框架下，默认是在要触发full GC前先执行一次young GC，并且两次GC之间能让应用程序稍微运行一小下，以期降低full GC的暂停时间（因为young GC会尽量清理了young gen的死对象，减少了full GC的工作量）。这是HotSpot VM里的奇葩. 并发GC的触发条件就不太一样。以CMS GC为例，它主要是定时去检查old gen的使用量，当使用量超过了触发比例就会启动一次CMS GC，对old gen做并发收集。 当然也可以简单的回答: Minor GC:指发生新生代的的垃圾收集动作，Minor GC 非常频繁，回收速度一般也比较快。 Full GC: 指收集整个堆，出现了 Full GC 经常会伴随至少一次的 Minor GC（并非绝对），Full GC 的速度一般会比 Minor GC 的慢 10 倍以上。 6.2 Full GC 触发条件及优化 System.gc()方法的调用 此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定,但很多情况下它会触发 Full GC,从而增加Full GC的频率,也即增加了间歇性停顿的次数。强烈影响系建议能不使用此方法就别使用，让虚拟机自己去管理它的内存，可通过设置-XX:+ DisableExplicitGC来禁止RMI调用System.gc。 老年代代空间不足 老年代空间只有在新生代对象转入及创建为大对象、大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误：java.lang.OutOfMemoryError: Java heap space 为避免以上两种状况引起的Full GC，调优时应尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间及不要创建过大的对象及数组。 方法区空间不足(jdk1.8 去掉了方法区) JVM规范中运行时数据区域中的方法区，在HotSpot虚拟机中又被习惯称为永生代或者永生区，Permanet Generation中存放的为一些class的信息、常量、静态变量等数据，当系统中要加载的类、反射的类和调用的方法较多时，Permanet Generation可能会被占满，在未配置为采用CMS GC的情况下也会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息： java.lang.OutOfMemoryError: PermGen space 为避免Perm Gen占满造成Full GC现象，可采用的方法为增大Perm Gen空间或转为使用CMS GC。 java虚拟机担保机制 由Eden区、survivor space1（From Space）区向survivor space2（To Space）区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，如果此时老年代空间也无法存储，就会担保失败，担保失败后JVM会进行Major GC 统计得到的Minor GC晋升到旧生代的平均大小大于老年代的剩余空间 这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。 例如程序第一次触发Minor GC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB， 则执行Full GC。 当新生代采用PS GC时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否 大于6MB，如小于，则触发对旧生代的回收。 堆中分配很大的对象 所谓大对象，是指需要大量连续内存空间的java对象，例如很长的数组，此种对象会直接进入老年代，而老年代虽然有很大的剩余空间，但是无法找到足够大的连续空间来分配给当前对象，此种情况就会触发JVM进行Full GC。 为了解决这个问题，CMS垃圾收集器提供了一个可配置的参数，即`-XX:+UseCMSCompactAtFullCollection开关参数，用于在“享受”完Full GC服务之后额外免费赠送一个碎片整理的过程，内存整理的过程无法并发的，空间碎片问题没有了，但提顿时间不得不变长了，JVM设计者们还提供了另外一个参数 -XX:CMSFullGCsBeforeCompaction,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的。 参考 《深入理解 Java 虚拟机：JVM 高级特性与最佳实践（第二版》 https://my.oschina.net/hosee/blog/644618 https://docs.oracle.com/javase/specs/jvms/se8/html/index.html "},"basic/data-struct.html":{"url":"basic/data-struct.html","title":"数据结构","keywords":"","body":"数据结构和算法数据结构和算法 "},"basic/data-struct/tree.html":{"url":"basic/data-struct/tree.html","title":"数组","keywords":"","body":"基本知识二叉树二叉排序树基本知识 二叉树 二叉树：二叉树是有限个结点的集合，这个集合或者是空集，或者是由一个根结点和两株互不相交的二叉树组成，其中一株叫根的做左子树，另一棵叫做根的右子树。 二叉树的性质： 性质1：在二叉树中第 i 层的结点数最多为 2(i−1)(i>=1)2^{(i-1)}(i>=1)2​(i−1)​​(i>=1) 性质2：高度为k的二叉树其结点总数最多为$2^k－1（ k >= 1）$ 性质3：对任意的非空二叉树 T ，如果叶结点的个数为 n0n_0n​0​​，而其度为 2 的结点数为n2n_2n​2​​，则：n0=n2+1n_0 = n_2 + 1n​0​​=n​2​​+1 满二叉树：深度为k且有$2^k －1个$结点的二叉树称为满二叉树 完全二叉树： 如果在一棵深度为$k (k≥1)$的满二叉树上删去第$k$层上最右的连续$j (0≤j≤2k-1)$个节点，就得到一棵深度为$k$的完全二叉树。(除最后一层外，每一层上的节点数均达到最大值；在最后一层上只缺少右边的若干结点）) 性质4：具有 n 个结点的完全二叉树的深度为 $log_2n + 1$ 注意： 仅有前序和后序遍历，不能确定一个二叉树，必须有中序遍历的结果 二叉排序树 "},"basic/data-struct/stack-queue.html":{"url":"basic/data-struct/stack-queue.html","title":"堆栈和队列","keywords":"","body":"堆栈和队列概念实战题 数据流中的第K大元素 (leetcode-703)滑动窗口最大值(leetcode-239)堆栈和队列 概念 Stack - First In Last Out (FILO) Array or Linked List Queue - First In First Out (FIFO) Array or Doubly Linked List 常见数据结构时间复杂度 实战题 有效的括号(leetcode-20) 示例: 输入: \"()[]{}\" 输出: true 输入: \"([)]\" 输出: false public static boolean isValid(String s) { Stack stack = new Stack<>(); HashMap parenMap = new HashMap() {{ put(')', '('); put(']', '['); put('}', '{'); }}; for (char c : s.toCharArray()) { if (!parenMap.containsKey(c)) { stack.push(c); } else if (stack.isEmpty() || !parenMap.get(c).equals(stack.pop())) { return false; } } return stack.isEmpty(); } 用栈实现队列(leetcode-232) push(x) -- 将一个元素放入队列的尾部。 pop() -- 从队列首部移除元素。 peek() -- 返回队列首部的元素。 empty() -- 返回队列是否为空。 示例: MyQueue queue = new MyQueue(); queue.push(1); queue.push(2); queue.peek(); // 返回 1 queue.pop(); // 返回 1 queue.empty(); // 返回 false 说明: 你只能使用标准的栈操作 -- 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。 你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。 假设所有操作都是有效的 （例如，一个空的队列不会调用 pop 或者 peek 操作）。 class MyQueue { Stack inStack; Stack outStack; /** * Initialize your data structure here. */ public MyQueue() { inStack = new Stack<>(); outStack = new Stack<>(); } /** * Push element x to the back of queue. */ public void push(int x) { inStack.push(x); } /** * Removes the element from in front of queue and returns that element. */ public int pop() { if (outStack.isEmpty()) { while (!inStack.isEmpty()) { outStack.push(inStack.pop()); } } return outStack.pop(); } /** * Get the front element. */ public int peek() { if (outStack.isEmpty()) { while (!inStack.isEmpty()) { outStack.push(inStack.pop()); } } return outStack.peek(); } /** * Returns whether the queue is empty. */ public boolean empty() { return outStack.isEmpty() && inStack.isEmpty(); } } 数据流中的第K大元素 (leetcode-703) 设计一个找到数据流中第K大元素的类（class）。注意是排序后的第K大元素，不是第K个不同的元素。 你的 KthLargest 类需要一个同时接收整数 k 和整数数组nums 的构造器，它包含数据流中的初始元素。每次调用 KthLargest.add，返回当前数据流中第K大的元素。 示例: int k = 3; int[] arr = [4,5,8,2]; KthLargest kthLargest = new KthLargest(3, arr); kthLargest.add(3); // returns 4 kthLargest.add(5); // returns 5 kthLargest.add(10); // returns 5 kthLargest.add(9); // returns 8 kthLargest.add(4); // returns 8说明: 你可以假设 nums 的长度≥ k-1 且k ≥ 1。 解答: class KthLargest { final PriorityQueue q; final int k; public KthLargest(int k, int[] nums) { this.k = k; q = new PriorityQueue<>(k); for (int num : nums) { add(num); } } public int add(int val) { if (q.size() 滑动窗口最大值(leetcode-239) 给定一个数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 返回滑动窗口中的最大值。 示例: 输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3 输出: [3,3,5,5,6,7] 解释: 滑动窗口的位置 最大值 --------------- ----- [1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 提示： 你可以假设 k 总是有效的，在输入数组不为空的情况下，1 ≤ k ≤ 输入数组的大小。 "},"core/data-base.html":{"url":"core/data-base.html","title":"数据存储","keywords":"","body":""},"core/cache.html":{"url":"core/cache.html","title":"缓存使用","keywords":"","body":""},"core/msg-queue.html":{"url":"core/msg-queue.html","title":"消息队列","keywords":"","body":"消息队列消息队列 消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题 实现高性能，高可用，可伸缩和最终一致性架构 使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ 消息队列使用场景 如何选择消息队列? 如何确保消息不会丢失? 如何处理消费过程中的重复消费? 消息积压了如何处理? 自己如何实现消息队列? 如何保证消息的有序性? Kafka RabbitMQ "},"core/msg-queue/scene-introduction.html":{"url":"core/msg-queue/scene-introduction.html","title":"消息队列使用场景","keywords":"","body":"一、消息队列使用场景1.异步处理2. 应用解耦3. 流量削锋4. 日志处理5. 消息通讯一、消息队列使用场景 以下介绍消息队列在实际应用中常用的使用场景。异步处理，应用解耦，流量削锋和消息通讯四个场景 1.异步处理 场景说明：用户注册后，需要发注册邮件和注册短信。传统的做法有两种 1.串行的方式；2.并行方式 （1）串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端 （2）并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并行的方式可以提高处理的时间 假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。 因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100） 小结：如以上案例描述，传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。如何解决这个问题呢？ 引入消息队列，将不是必须的业务逻辑，异步处理。改造后的架构如下： 按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是50毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍. 2. 应用解耦 场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。如下图 传统模式的缺点： 假如库存系统无法访问，则订单减库存将失败，从而导致订单失败 订单系统与库存系统耦合 如何解决以上问题呢？引入应用消息队列后的方案，如下图： 订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功 库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作 假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦. 3. 流量削锋 流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛 应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。 可以控制活动的人数 可以缓解短时间内高流量压垮应用 用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面 秒杀业务根据消息队列中的请求信息，再做后续处理 4. 日志处理 日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下: 日志采集客户端，负责日志数据采集，定时写受写入Kafka队列 Kafka消息队列，负责日志数据的接收，存储和转发 日志处理应用：订阅并消费kafka队列中的日志数据 常见日志处理方案: (1)Kafka：接收用户日志的消息队列 (2)Logstash：做日志解析，统一成JSON输出给Elasticsearch (3)Elasticsearch：实时日志分析服务的核心技术，一个schemaless，实时的数据存储服务，通过index组织数据，兼具强大的搜索和统计功能 (4)Kibana：基于Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因 5. 消息通讯 消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等 点对点通讯： 客户端A和客户端B使用同一队列，进行消息通讯。 聊天室通讯： 客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。 以上实际是消息队列的两种消息模式，点对点或发布订阅模式。模型为示意图，供参考。 "},"core/msg-queue/pile-up.html":{"url":"core/msg-queue/pile-up.html","title":"消息积压了如何处理?","keywords":"","body":"消息积压了如何处理?优化性能来避免消息积压1.发送端性能优化2.消费端性能优化消息积压了该如何处理?总结扩展参考消息积压了如何处理? 在使用消息队列遇到的问题中，消息积压这个问题，应该是最常遇到的问题了，并且，这个问题还不太好解决。 我们都知道，消息积压的直接原因，一定是系统中的某个部分出现了性能问题，来不及处理上游发送的消息，才会导致消息积压。 所以，我们先来分析下，在使用消息队列时，如何来优化代码的性能，避免出现消息积压。然后再来看看，如果你的线上系统出现了消息积压，该如何进行紧急处理，最大程度地避免消息积压对业务的影响。 优化性能来避免消息积压 在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者这一收一发两部分的业务逻辑中。对于消息队列本身的性能，你作为使用者，不需要太关注。为什么这么说呢? 主要原因是，对于绝大多数使用消息队列的业务来说，消息队列本身的处理能力要远大于业务系统的处理能力。主流消息队列的单个节点，消息收发的性能可以达到每秒钟处理几万至几十万条消息的水平，还可以通过水平扩展Broker的实例数成倍地提升处理能力。而一般的业务系统需要处理的业务逻辑远比消息队列要复杂，单个节点每秒钟可以处理几百到几千次请求，已经可以算是性能非常好的了。所以，对于消息队列的性能优化，我们更关 注的是，在消息的收发两端，我们的业务代码怎么和消息队列配合，达到一个最佳的性能。 1.发送端性能优化 发送端业务代码的处理性能，实际上和消息队列的关系不大，因为一般发送端都是先执行自己的业务逻辑，最后再发送消息。如果说，你的代码发送消息的性能上不去，你需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的。 对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能。为什么这么说呢? 我们知道Producer发送消息的过程，Producer 发消息给Broker, Broker收到消息后返回确认响应，这是一次完整的交互。假设这一次交互的平均时延是1ms,我们把这1ms的时间分解开，它包括了下面这些步骤的耗时: 发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时; 发送消息和返回响应在网络传输中的耗时; Broker 处理消息的时延。 如果是单线程发送，每次只发送1条消息，那么每秒只能发送1000ms / 1ms * 1条/ms =1000条消息，这种情况下并不能发挥出消息队列的全部实力。无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能。至于到底是选择批量发送还是增加并发，主要取决于发送端程序的业务性质。简单来说，只要能够满足你的性能要求，怎么实现方便就怎么实现。 比如说，你的消息发送端是一个微服务，主要接受RPC请求处理在线业务。很自然的,微服务在处理每次请求的时候，就在当前线程直接发送消息就可以了，因为所有RPC框架都是多线程支持多并发的，自然也就实现了并行发送消息。并且在线业务比较在意的是请求响应时延，选择批量发送必然会影响RPC服务的时延。这种情况，比较明智的方式就是通过并发来提升发送性能。 如果你的系统是一个离线分析系统，离线系统在性能上的需求是什么呢?它不关心时延，更注重整个系统的吞吐量。发送端的数据都是来自于数据库，这种情况就更适合批量发送，你可以批量从数据库读取数据，然后批量来发送消息，同样用少量的并发就可以获得非常高的吞吐量。 2.消费端性能优化 使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。 要是消费速度一直比生产速度慢，时间长了，整个系统就会出现问题，要么，消息队列的存储被填满无法提供服务，要么消息丢失，这对于整个系统来说都是严重故障。 所以，我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。 消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是(若使用Kafka或RocketMQ)，在扩容Consumer的实例数量的同时，必须同步扩容主题中的分区(partition)(也叫队列)数量，确保Consumer的实例数和分区数量是相等的。如果Consumer的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因是因为对于消费者来说，在每个分区上实际上只能支持单线程消费。 很多消费程序，是这样来解决消费慢的问题的: 它收消息处理的业务逻辑可能比较慢，也很难再优化了，为了避免消息积压，在收到消息的OnMessage方法中，不处理任何业务逻辑，把这个消息放到一个内存队列里面就返回了。然后它可以启动很多的业务线程，这些业务线程里面是真正处理消息的业务逻辑，这些线程从内存队列里取消息处理，这样它就解决了单个Consumer不能并行消费的问题。 这个方法是不是很完美地实现了并发消费?请注意，这是一个非常常见的错误方法!为什么错误?因为会丢消息。如果收消息的节点发生宕机，在内存队列中还没来及处理的这些消息就会丢失。 消息积压了该如何处理? 还有一种消息积压的情况是，日常系统正常运转的时候，没有积压或者只有少量积压很快就消费掉了，但是某一个时刻，突然就开始积压消息并且积压持续上涨。这种情况下需要你在短时间内找到消息积压的原因，迅速解决问题才不至于影响业务。 导致突然积压的原因肯定是多种多样的，不同的系统、不同的情况有不同的原因，不能一概而论。但是，我们排查消息积压原因，是有一些相对固定而且比较有效的方法的。 能导致积压突然增加，最粗粒度的原因，只有两种:要么是发送变快了，要么是消费变慢了。 大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。如果是单位时间发送的消息增多，比如说是赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的方法是通过扩容消费端的实例数来提升总体的消费能力。 如果短时间内没有足够的服务器资源进行扩容,没办法的办法是，将系统降级，通过关闭一些不重要的业务减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。 还有一种不太常见的情况，你通过监控发现，无论是发送消息的速度还是消费消息的速度和原来都没什么变化，这时候你需要检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。 如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。 总结 本文主要讨论了2个问题，一个是如何在消息队列的收发两端优化系统性能，提前预防消息积压。另外一个问题是，当系统发生消息积压了之后，该如何处理。 优化消息收发性能，预防消息积压的方法有两种，增加批量或者是增加并发，在发送端这两种方法都可以使用，在消费端需要注意的是，增加并发需要同步扩容分区数量，否则是起不到效果的。 对于系统发生消息积压的情况，需要先解决积压，再分析原因，毕竟保证系统的可用性是首先要解决的问题。快速解决积压的方法就是通过水平扩容增加Consumer的实例数量。实在不能扩容考虑服务降级. 扩展 是否可在消费端批量消费以及可能存在的问题? 批量消费有意义的场景要求： 要求消费端能够批量处理或者开启多线程进行单条处理，比如批量入库 批量消费的局限性： 需要一个整体ack的机制，一旦一条靠前的消息消费失败，可能会引起很多消息重试。 对实时性要求不能太高，批量消费需要Broker积累到一定消费数据才会发送到Consumer 参考 消息积压了该如何处理？ "},"core/msg-queue/kafka.html":{"url":"core/msg-queue/kafka.html","title":"Kafka","keywords":"","body":"1. Kafka 概述2. Kafka中的术语解释3. 生产者3.1 负载均衡（partition 会均衡分布到不同 broker 上）3.2 批量发送3.3 压缩（GZIP 或 Snappy）4. 消费者4.1 Consumer Group4.2 Push vs. Pull1. Kafka 概述 Kafka 是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由 LinkedIn 公司开发，使用Scala 语言编写，目前是 Apache 的开源项目。 主要应用场景是：日志收集系统和消息系统。 Kafka主要设计目标如下： 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 支持在线水平扩展 2. Kafka中的术语解释 在深入理解Kafka之前，先介绍一下Kafka中的术语。下图展示了Kafka的相关术语以及之间的关系： 上图中一个topic配置了3个partition。Partition1有两个offset：0和1。Partition2有4个offset。Partition3有1个offset。副本的id和副本所在的机器的id恰好相同。 如果一个topic的副本数为3，那么Kafka将在集群中为每个partition创建3个相同的副本。集群中的每个broker存储一个或多个partition。多个producer和consumer可同时生产和消费数据。 broker： Kafka 集群包含一个或多个服务器，服务器节点称为broker，负责消息存储和转发 broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。 如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。 如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。 topic： 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处） 类似于数据库的表名 partition： topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。 offset： kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka Producer： 生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。 Consumer： 消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。 Consumer Group： 每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制给consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。 Zookeeper： 保存着集群 broker、topic、partition 等 meta 数据；另外，还负责 broker 故障发现，partition leader 选举，负载均衡等功能 Leader 每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。 Follower Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。 kafka架构: 如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。 3. 生产者 3.1 负载均衡（partition 会均衡分布到不同 broker 上） 由于消息 topic 由多个 partition 组成，且 partition 会均衡分布到不同 broker 上，因此，为了有 效利用 broker 集群的性能，提高消息的吞吐量，producer 可以通过随机或者 hash 等方式，将消 息平均发送到多个 partition 上，以实现负载均衡。 3.2 批量发送 是提高消息吞吐量重要的方式，Producer 端可以在内存中合并多条消息后，以一次请求的方式发 送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响 了消息的实时性，相当于以时延代价，换取更好的吞吐量。 3.3 压缩（GZIP 或 Snappy） Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后，在 Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大 数据处理上，瓶颈往往体现在网络上而不是 CPU（压缩和解压会耗掉部分 CPU 资源）。 4. 消费者 4.1 Consumer Group 同一 Consumer Group 中的多个 Consumer 实例，不同时消费同一个 partition，等效于队列模 式。partition 内消息是有序的，Consumer 通过 pull 方式消费消息。Kafka 不删除已消费的消息 对于 partition，顺序读写磁盘数据，以时间复杂度 O(1)方式提供消息持久化能力。 使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。 这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。 实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。 4.2 Push vs. Pull 作为一个消息系统，Kafka遵循了传统的方式，选择由Producer向broker push消息并由Consumer从broker pull消息。一些logging-centric system，比如Facebook的Scribe和Cloudera的Flume，采用push模式。事实上，push模式和pull模式各有优劣。 push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成Consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据Consumer的消费能力以适当的速率消费消息。 对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 关于kafka更多文章: https://www.cnblogs.com/frankdeng/p/9310684.html https://kafka.apache.org/documentation/ "},"core/msg-queue/rabbit.html":{"url":"core/msg-queue/rabbit.html","title":"RabbitMQ","keywords":"","body":""},"framework/spring.html":{"url":"framework/spring.html","title":"Spring","keywords":"","body":""},"framework/mybatis.html":{"url":"framework/mybatis.html","title":"Mybatis","keywords":"","body":""},"framework/netty.html":{"url":"framework/netty.html","title":"Netty","keywords":"","body":""}}